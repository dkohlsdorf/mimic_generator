{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Whistles From Box 2 Box\n",
    "\n",
    "We need to extract whistles played through the ocean and recorded by a box.\n",
    "\n",
    "### !!!! CAREFULL THE CUTS WONT BE PERFECT AND THE LABELING WILL NEITHER CHECK ALL FILES\n",
    "\n",
    "## Basic Idea\n",
    "Use the original file to find gaps.\n",
    "Align the recorded file to the original file (manually).\n",
    "Find all gaps that are large enough in the original file:\n",
    "    $$(gap_{i, start}, gap_{i, stop})$$.\n",
    "    \n",
    "Use the gaps to find whistles. Since the extractor is not perfect, we classify each region using the trace and\n",
    "a nearest neighbor based solution based on dtw."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from mimic_utils.spectrogram import *\n",
    "from mimic_utils.whistle_tracer import *\n",
    "from mimic_utils.params import * \n",
    "from scipy.io import wavfile\n",
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "from fastdtw import fastdtw\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The algorithms to extract the audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wtrace(audio):    \n",
    "    spec = fwd_spectrogram(audio, FFT_WIN, FFT_STEP)\n",
    "    whistle_trace, _  = trace(spec, TRACE_RAD, SMOOTH_ENT)\n",
    "    whistle_trace = whistle_trace[:-1]\n",
    "    whistle_trace = whistle_trace[whistle_trace > 0.0]\n",
    "    hi  = np.max(whistle_trace)\n",
    "    lo = np.min(whistle_trace)\n",
    "    return (whistle_trace - lo) / (hi - lo)\n",
    "\n",
    "\n",
    "class Classifier:\n",
    "    \n",
    "    def __init__(self, folder):\n",
    "        self.templates = {}\n",
    "        for filename in os.listdir(folder):\n",
    "            if filename.endswith(\".wav\"):\n",
    "                print(\"Loading Classifier Template: {}\".format(filename))\n",
    "                basename = filename.split(\"/\")[-1].replace(\".wav\", \"\")\n",
    "                _, data = wavfile.read(\"{}/{}\".format(folder, filename))\n",
    "                self.templates[basename] = wtrace(data[:, 0])\n",
    "                \n",
    "    def nn(self, trace):\n",
    "        min_label = -1\n",
    "        min_dist  = float('inf') \n",
    "        for label, template in self.templates.items():\n",
    "            dist, path = fastdtw(trace, template, dist=euclidean)\n",
    "            print(\"{} {}\", label, dist)\n",
    "            if dist < min_dist:\n",
    "                min_dist = dist\n",
    "                min_label = label\n",
    "        print(\"Min Dist: {} Min Label: {}\".format(min_dist, min_label))\n",
    "        return min_label\n",
    "namer = Classifier(\"originals/\")\n",
    "\n",
    "for label,t in namer.templates.items():\n",
    "    plt.plot(t)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract the 00 variations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_all(original, recorded, output, classifier, border = 30000, min_gap_size = 100000, th = 0.2):\n",
    "    basename = recorded.split(\"/\")[-1].replace(\".wav\", \"\")\n",
    "    print(basename)\n",
    "    _,  data_original = wavfile.read(original)\n",
    "    fs, data_box      = wavfile.read(recorded)\n",
    "    data = (data_original[:, 0] + 32768) / (32768 + 32767)    \n",
    "\n",
    "    last_sample = 0\n",
    "    start_i = 0    \n",
    "    gaps = []\n",
    "    \n",
    "    print(\"Using templates\")\n",
    "    for label, t in classifier.templates.items():\n",
    "        plt.title(label)\n",
    "        plt.plot(t)\n",
    "        plt.show()\n",
    "    \n",
    "    print(\"Searching gaps\")\n",
    "    n = len(data_original)\n",
    "    for i in range(10, n):\n",
    "        sample = np.sum(data[i - 10:i]) / 10        \n",
    "        if sample < th and last_sample >= th and i - start_i > min_gap_size:\n",
    "            print(\"STOP {} {} {} %done {} {}\".format(start_i / fs, i / fs, (i - start_i) / fs, (i / n) * 100, len(gaps)))\n",
    "            gaps.append([start_i, i])        \n",
    "        if sample >= th and last_sample < th:\n",
    "            start_i = i\n",
    "        last_sample = sample\n",
    "\n",
    "    print(\"Processing gaps\")\n",
    "    for i in range(1, len(gaps)):  \n",
    "        _, start = gaps[i - 1]\n",
    "        stop, _  = gaps[i]\n",
    "        print(\"Tracing {} {}\".format(start / fs, stop / fs))\n",
    "        trace = wtrace(data_original[start - border: stop + border, 0])\n",
    "        print(\"Traced!\")\n",
    "        name = classifier.nn(trace)        \n",
    "        filename = '{}/{}_{}_{}.wav'.format(output, name, basename, start)\n",
    "        print(\"DETECTED: \", filename)\n",
    "        wavfile.write(filename, fs, data_box[start - border: stop + border, 0])\n",
    "\n",
    "output     = \"00\" \n",
    "original   = '/Users/daniel.kohlsdorf/Desktop/00-all-whistles-2019-synth--04--18.wav'\n",
    "recorded   = '/Users/daniel.kohlsdorf/Desktop/00_chat1-2019-06-23T123304-192k.wav'\n",
    "extract_all(original, recorded, output, namer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
