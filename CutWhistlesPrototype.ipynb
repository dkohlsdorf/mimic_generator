{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Whistles From Box 2 Box\n",
    "\n",
    "We need to extract whistles played through the ocean and recorded by a box.\n",
    "\n",
    "## Basic Idea\n",
    "Use the original file to find gaps.\n",
    "Align the recorded file to the original file (manually).\n",
    "Find all gaps that are large enough in the original file:\n",
    "    $$(gap_{i, start}, gap_{i, stop})$$.\n",
    "    \n",
    "Use the gaps to find whistles. Since the extractor is not perfect, we classify each region using the trace and\n",
    "a nearest neighbor based solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from mimic_utils.spectrogram import *\n",
    "from mimic_utils.whistle_tracer import *\n",
    "from mimic_utils.params import * \n",
    "from scipy.io import wavfile\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The algorithms to extract the audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Classifier Template: sar.wav\n",
      "Loading Classifier Template: sca.wav\n",
      "Loading Classifier Template: gra.wav\n"
     ]
    }
   ],
   "source": [
    "def wtrace(audio):\n",
    "    spec = fwd_spectrogram(data_original[start - border: stop + border, 0], FFT_WIN, FFT_STEP)\n",
    "    whistle_trace, _  = trace(spec, TRACE_RAD, SMOOTH_ENT)   \n",
    "    lo = min(whistle_trace)\n",
    "    hi = max(whistle_trace)\n",
    "    return (whistle_trace - lo) / (hi - lo)\n",
    "\n",
    "\n",
    "class Classifier:\n",
    "    \n",
    "    def __init__(self, folder):\n",
    "        self.templates = {}\n",
    "        for filename in os.listdir(folder):\n",
    "            if filename.endswith(\".wav\"):\n",
    "                print(\"Loading Classifier Template: {}\".format(filename))\n",
    "                basename = filename.split(\"/\")[-1].replace(\".wav\", \"\")\n",
    "                data = wavfile.read(\"{}/{}\".format(folder, filename))\n",
    "                self.templates[basename] = wtrace(data)\n",
    "        \n",
    "    def nn(self, trace):\n",
    "        min_label = -1\n",
    "        min_dist  = float('inf') \n",
    "        for label, template in self.templates.items():\n",
    "            n = min(len(trace), len(template))\n",
    "            dist = np.sum(np.square(trace[0:n], template[0:n]))\n",
    "            if dist < min_dist:\n",
    "                min_dist = dist\n",
    "                min_label = label\n",
    "        print(\"Min Dist: {} Min Label: {}\".format(min_dist, min_label))\n",
    "        return min_label\n",
    "    \n",
    "classifier = Classifier(\"originals/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_all(original, recorded, output, classifier, border = 30000, min_gap_size = 100000, th = 0.2):\n",
    "    basename = recorded.split(\"/\")[-1].replace(\".wav\", \"\")\n",
    "    print(basename)\n",
    "    _,  data_original = wavfile.read(original)\n",
    "    fs, data_box      = wavfile.read(recorded)\n",
    "    data = (data_original[:, 0] + 32768) / (32768 + 32767)    \n",
    "\n",
    "    last_sample = 0\n",
    "    start_i = 0    \n",
    "    gaps = []\n",
    "    \n",
    "    print(\"Searching gaps\")\n",
    "    n = len(data_original)\n",
    "    for i in range(2 * 190000, 9 * 190000):\n",
    "        sample = np.sum(data[i - 10:i]) / 10        \n",
    "        if sample < th and last_sample >= th and i - start_i > min_gap_size:\n",
    "            print(\"STOP {} {} {} %done {} {}\".format(start_i / fs, i / fs, (i - start_i) / fs, (i / n) * 100, len(gaps)))\n",
    "            gaps.append([start_i, i])        \n",
    "        if sample >= th and last_sample < th:\n",
    "            start_i = i\n",
    "        last_sample = sample\n",
    "\n",
    "    print(\"Processing gaps\")\n",
    "    for i in range(1, len(gaps)):  \n",
    "        _, start = gaps[i - 1]\n",
    "        stop, _  = gaps[i]\n",
    "        print(\"Tracing {} {}\".format(start / fs, stop / fs))\n",
    "        trace = wtrace(data_original[start - border: stop + border, 0])\n",
    "        print(\"Traced!\")\n",
    "        name = classifier.nn(trace)\n",
    "        filename = '{}/{}_{}_{}.wav'.format(output, name, basename, start)\n",
    "        print(\"DETECTED: \", filename)\n",
    "        wavfile.write(filename, fs, data_box[start - border: stop + border, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract the 00 variations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00_chat1-2019-06-23T123304-192k\n",
      "Searching gaps\n",
      "STOP 3.6984427083333333 4.573083333333333 0.874640625 %done 1.3291988580690497 0\n",
      "STOP 6.28975 7.156640625 0.866890625 %done 2.080127969027586 1\n",
      "Processing gaps\n",
      "Tracing 4.573083333333333 6.28975\n",
      "Traced!\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable numpy.float64 object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-243-8aa7c6a000a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0moriginal\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0;34m'/Users/daniel.kohlsdorf/Desktop/00-all-whistles-2019-synth--04--18.wav'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mrecorded\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0;34m'/Users/daniel.kohlsdorf/Desktop/00_chat1-2019-06-23T123304-192k.wav'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mextract_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecorded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-240-9ac8a32e15e1>\u001b[0m in \u001b[0;36mextract_all\u001b[0;34m(original, recorded, output, classifier, border, min_gap_size, th)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mtrace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwtrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_original\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mborder\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstop\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mborder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Traced!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'{}/{}_{}_{}.wav'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"DETECTED: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-242-ff4ce4f05aee>\u001b[0m in \u001b[0;36mnn\u001b[0;34m(self, trace)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemplate\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtemplates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemplate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0mdist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemplate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdist\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mmin_dist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0mmin_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable numpy.float64 object"
     ]
    }
   ],
   "source": [
    "output     = \"00\" \n",
    "original   = '/Users/daniel.kohlsdorf/Desktop/00-all-whistles-2019-synth--04--18.wav'\n",
    "recorded   = '/Users/daniel.kohlsdorf/Desktop/00_chat1-2019-06-23T123304-192k.wav'\n",
    "extract_all(original, recorded, output, classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract 07 variations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output     = \"07\" \n",
    "original   = '/Users/daniel.kohlsdorf/Desktop/'\n",
    "recorded   = '/Users/daniel.kohlsdorf/Desktop/'\n",
    "extract_all(original, recorded, output, classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
